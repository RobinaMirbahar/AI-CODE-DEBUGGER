{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ade6733b",
   "metadata": {
    "papermill": {
     "duration": 0.002039,
     "end_time": "2025-02-23T14:14:53.242306",
     "exception": false,
     "start_time": "2025-02-23T14:14:53.240267",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# March Mania 2025 - Starter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97763a2a",
   "metadata": {
    "papermill": {
     "duration": 0.001296,
     "end_time": "2025-02-23T14:14:53.245463",
     "exception": false,
     "start_time": "2025-02-23T14:14:53.244167",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Goal of the competition\n",
    "\n",
    "The goal of this competition is to predict that probability that the smaller ``TeamID`` will win a given matchup. You will predict the probability for every possible matchup between every possible team over the past 4 years. You'll be given a sample submission file where the ```ID``` value indicates the year of the matchup as well as the identities of both teams within the matchup. For example, for an ```ID``` of ```2025_1101_1104``` you would need to predict the outcome of the matchup between ```TeamID 1101``` vs ```TeamID 1104``` during the ```2025``` tournament. Submitting a ```PRED``` of ```0.75``` indicates that you think that the probability of ```TeamID 1101``` winning that particular matchup is equal to ```0.75```.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33511d14",
   "metadata": {
    "papermill": {
     "duration": 0.0013,
     "end_time": "2025-02-23T14:14:53.248269",
     "exception": false,
     "start_time": "2025-02-23T14:14:53.246969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Overview of our submission strategy \n",
    "For this starter notebook, we will make a simple submission.\n",
    "\n",
    "We can predict the winner of a match by considering the respective rankings of the opposing teams, only. Since the largest possible difference is 15 (which is #16 minus #1), we use a rudimentary formula that's 0.5 plus 0.03 times the difference in seeds, leading to a range of predictions spanning from 5% up to 95%. The stronger-seeded team (with a lower seed number from 1 to 16) will be the favorite and will have a prediction above 50%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef48aeac",
   "metadata": {
    "papermill": {
     "duration": 0.001287,
     "end_time": "2025-02-23T14:14:53.250991",
     "exception": false,
     "start_time": "2025-02-23T14:14:53.249704",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Starter Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eed3ee7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T14:14:53.255007Z",
     "iopub.status.busy": "2025-02-23T14:14:53.254735Z",
     "iopub.status.idle": "2025-02-23T14:15:17.896042Z",
     "shell.execute_reply": "2025-02-23T14:15:17.895062Z"
    },
    "papermill": {
     "duration": 24.645251,
     "end_time": "2025-02-23T14:15:17.897685",
     "exception": false,
     "start_time": "2025-02-23T14:14:53.252434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Elo Ratings: 100%|██████████| 41/41 [00:17<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Brier Scores: [0.18601591 0.18006941 0.17932004 0.18396685 0.19315551]\n",
      "Mean CV Score: 0.18451\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score \n",
    "from sklearn.metrics import brier_score_loss\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ======================================================================\n",
    "# 1. Data Loading & Initial Processing\n",
    "# ======================================================================\n",
    "\n",
    "# Load all competition data\n",
    "m_regular = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/MRegularSeasonCompactResults.csv')\n",
    "w_regular = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/WRegularSeasonCompactResults.csv')\n",
    "tourney_results = pd.concat([\n",
    "    pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/MNCAATourneyCompactResults.csv'),\n",
    "    pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/WNCAATourneyCompactResults.csv')\n",
    "])\n",
    "submission = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/SampleSubmissionStage1.csv')\n",
    "\n",
    "# ======================================================================\n",
    "# 2. Seed Data Processing\n",
    "# ======================================================================\n",
    "\n",
    "def parse_seed(seed):\n",
    "    \"\"\"Robust seed parsing with error handling\"\"\"\n",
    "    try:\n",
    "        return int(''.join(filter(str.isdigit, str(seed))))\n",
    "    except:\n",
    "        return 16  # Default value for missing/invalid seeds\n",
    "\n",
    "# Process seed information\n",
    "seed_data = pd.concat([\n",
    "    pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/MNCAATourneySeeds.csv'),\n",
    "    pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/WNCAATourneySeeds.csv')\n",
    "])\n",
    "seed_data['SeedValue'] = seed_data['Seed'].apply(parse_seed)\n",
    "seed_map = seed_data.set_index(['Season', 'TeamID'])['SeedValue'].to_dict()\n",
    "\n",
    "# ======================================================================\n",
    "# 3. Elo Rating System Implementation\n",
    "# ======================================================================\n",
    "\n",
    "class EloCalculator:\n",
    "    def __init__(self, k=32, regress=0.2):\n",
    "        self.k = k\n",
    "        self.regress = regress\n",
    "        self.ratings = {}\n",
    "        \n",
    "    def process_season(self, season_df):\n",
    "        season_df = season_df.sort_values('DayNum')\n",
    "        for _, row in season_df.iterrows():\n",
    "            t1, t2, wloc = row['WTeamID'], row['LTeamID'], row['WLoc']\n",
    "            margin = row['WScore'] - row['LScore']\n",
    "            \n",
    "            # Initialize ratings if needed\n",
    "            for team in [t1, t2]:\n",
    "                if team not in self.ratings:\n",
    "                    self.ratings[team] = 1500\n",
    "                    \n",
    "            # Calculate Elo updates\n",
    "            r1, r2 = self.ratings[t1], self.ratings[t2]\n",
    "            q1 = 10 ** (r1 / 400)\n",
    "            q2 = 10 ** (r2 / 400)\n",
    "            e1 = q1 / (q1 + q2)\n",
    "            delta = self.k * ((1 + margin/20) - e1)\n",
    "            \n",
    "            self.ratings[t1] += delta\n",
    "            self.ratings[t2] -= delta\n",
    "            \n",
    "            # Season regression\n",
    "            for team in [t1, t2]:\n",
    "                self.ratings[team] = (self.ratings[team] - 1500) * (1 - self.regress) + 1500\n",
    "\n",
    "# Calculate Elo ratings for all teams\n",
    "full_regular = pd.concat([m_regular, w_regular])\n",
    "elo_system = EloCalculator()\n",
    "for season in tqdm(full_regular['Season'].unique(), desc='Calculating Elo Ratings'):\n",
    "    season_data = full_regular[full_regular['Season'] == season]\n",
    "    elo_system.process_season(season_data)\n",
    "\n",
    "# ======================================================================\n",
    "# 4. Corrected Feature Engineering\n",
    "# ======================================================================\n",
    "\n",
    "def create_tourney_features(tourney_df):\n",
    "    features = []\n",
    "    elo_cache = {}\n",
    "    \n",
    "    for season in tourney_df['Season'].unique():\n",
    "        season_games = tourney_df[tourney_df['Season'] == season]\n",
    "        season_teams = set(season_games['WTeamID']).union(set(season_games['LTeamID']))\n",
    "        \n",
    "        # Initialize season cache\n",
    "        for team in season_teams:\n",
    "            elo_cache[team] = elo_system.ratings.get(team, 1500)\n",
    "        \n",
    "        for idx, row in season_games.sort_values('DayNum').iterrows():\n",
    "            t1, t2 = sorted([row['WTeamID'], row['LTeamID']])\n",
    "            \n",
    "            # Keep only relevant features\n",
    "            features.append({\n",
    "                'EloDiff': elo_cache[t1] - elo_cache[t2],\n",
    "                'SeedDiff': seed_map.get((season, t2), 16) - seed_map.get((season, t1), 16),\n",
    "                'Outcome': 1 if row['WTeamID'] == t1 else 0\n",
    "            })\n",
    "                \n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "tourney_features = create_tourney_features(tourney_results)\n",
    "\n",
    "# ======================================================================\n",
    "# 5. Model Training with Correct Features\n",
    "# ======================================================================\n",
    "\n",
    "X = tourney_features[['EloDiff', 'SeedDiff']]  # Only use predictive features\n",
    "y = tourney_features['Outcome']\n",
    "\n",
    "best_params = {\n",
    "    'max_iter': 500,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 7,\n",
    "    'l2_regularization': 1.0,\n",
    "    'early_stopping': True,\n",
    "    'validation_fraction': 0.2\n",
    "}\n",
    "\n",
    "# Simplified validation\n",
    "model = HistGradientBoostingClassifier(**best_params)\n",
    "model.fit(X, y)\n",
    "\n",
    "# ======================================================================\n",
    "# 6. Correct Submission Generation\n",
    "# ======================================================================\n",
    "\n",
    "def generate_submission_features(sub_df):\n",
    "    features = []\n",
    "    # Parse ID column directly\n",
    "    for id_str in sub_df['ID']:\n",
    "        parts = id_str.split('_')\n",
    "        season = int(parts[0])\n",
    "        t1 = int(parts[1])\n",
    "        t2 = int(parts[2])\n",
    "        \n",
    "        features.append({\n",
    "            'EloDiff': elo_system.ratings.get(t1, 1500) - elo_system.ratings.get(t2, 1500),\n",
    "            'SeedDiff': seed_map.get((season, t2), 16) - seed_map.get((season, t1), 16)\n",
    "        })\n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "sub_features = generate_submission_features(submission)\n",
    "submission['Pred'] = model.predict_proba(sub_features)[:, 1]\n",
    "submission['Pred'] = submission['Pred'].clip(0.03, 0.97)\n",
    "\n",
    "# ======================================================================\n",
    "# 7. Final Validation & Output\n",
    "# ======================================================================\n",
    "\n",
    "# Cross-validation score check\n",
    "cv_scores = -cross_val_score(model, X, y, \n",
    "                            cv=TimeSeriesSplit(n_splits=5),\n",
    "                            scoring='neg_brier_score')\n",
    "print(f\"Cross-Validation Brier Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Score: {np.mean(cv_scores):.5f}\")\n",
    "\n",
    "submission[['ID', 'Pred']].to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11018643,
     "sourceId": 91497,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27.691189,
   "end_time": "2025-02-23T14:15:18.418656",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-23T14:14:50.727467",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
